{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HiFIC_torch_colab_demo.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpm_NksQMtNr"
      },
      "source": [
        "# HiFIC Demo\n",
        "Compress arbitrary images in Colab using a pretrained neural compression model. This is a Pytorch port of the [High-Fidelity Image Compression](https://hific.github.io/) project - see the [Github repo](https://github.com/Justin-Tan/high-fidelity-generative-compression) for the source.\n",
        "\n",
        "Execute all cells in sequence to see the results of compression on a default image, or upload your own images to be compressed by following the steps in the notebook.\n",
        "\n",
        "Some sample reconstructions from the compressed format can be found [here](https://github.com/Justin-Tan/high-fidelity-generative-compression/blob/master/assets/EXAMPLES.md). For detailed usage instructions please see [the user's guide](https://github.com/Justin-Tan/high-fidelity-generative-compression/blob/master/assets/USAGE_GUIDE.md).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umer7W0VbITT"
      },
      "source": [
        "## Setup Colab Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M227Y3aWcott",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6a3c447-5cf5-4d2b-df8c-551016b4905d"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import urllib\n",
        "import zipfile\n",
        "import collections\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import Javascript\n",
        "from IPython.core.display import display, HTML\n",
        "from torchvision import transforms\n",
        "from compress import prepare_model, prepare_dataloader, compress_and_save, load_and_decompress\n",
        "\n",
        "INPUT_DIR = '/content/files'\n",
        "STAGING_DIR = '/content/stage'\n",
        "OUT_DIR = '/content/out'\n",
        "CKPT_DIR = '/content/checkpoint'\n",
        "DEFAULT_IMAGE_PREFIX = 'https://storage.googleapis.com/hific/clic2020/images/originals/'\n",
        "\n",
        "File = collections.namedtuple('File', ['output_path', 'compressed_path', 'num_bytes', 'bpp'])\n",
        "\n",
        "_ = [os.makedirs(dir, exist_ok=True) for dir in (INPUT_DIR, STAGING_DIR, OUT_DIR, CKPT_DIR)]\n",
        "original_sizes = dict()\n",
        "\n",
        "# Function to download default image\n",
        "def get_default_image(output_dir, image_choice=\"portrait\"):\n",
        "    image_ID = dict(\n",
        "        portrait=\"ad249bba099568403dc6b97bc37f8d74.png\"\n",
        "    )[image_choice]\n",
        "    default_image_url = os.path.join(DEFAULT_IMAGE_PREFIX, image_ID)\n",
        "    output_path = os.path.join(output_dir, os.path.basename(default_image_url))\n",
        "    urllib.request.urlretrieve(default_image_url, output_path)\n",
        "\n",
        "# Function to calculate bpp\n",
        "def get_bpp(image_dimensions, num_bytes):\n",
        "    w, h = image_dimensions\n",
        "    return num_bytes * 8 / (w * h)\n",
        "\n",
        "# Adaptive quantization implementation\n",
        "def extract_rate_distribution(model, image_path):\n",
        "    \"\"\"\n",
        "    Extract rate distribution using HiFiC encoder.\n",
        "    \"\"\"\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((512, 512)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    image_tensor = transform(img).unsqueeze(0).cuda()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        latent = model.Encoder(image_tensor)  # Accessing Encoder instead of encoder\n",
        "        rates = torch.sum(latent.abs(), dim=1)\n",
        "    return rates.cpu().numpy()\n",
        "\n",
        "def adaptive_quantization(model, image_path, uniform_quantizer=16):\n",
        "    \"\"\"\n",
        "    Perform adaptive quantization guided by HiFiC rate distribution.\n",
        "    \"\"\"\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    # First-pass: Uniform quantization\n",
        "    uniform_rates = np.log2(np.abs(img_array) + 1).sum(axis=-1)\n",
        "\n",
        "    # Get rate distribution from HiFiC\n",
        "    rate_map = extract_rate_distribution(model, image_path)\n",
        "\n",
        "    # Resize the image to match the number of quantizers (1024 values)\n",
        "    # Resizing to 32x32 (or any other desired size)\n",
        "    resized_img = img.resize((32, 32))  # This will reduce the image to 32x32\n",
        "\n",
        "    # Flatten the image to match the quantizer's number of values\n",
        "    resized_img_array = np.array(resized_img).reshape(-1, 3)  # Shape will be (1024, 3)\n",
        "\n",
        "    # Adaptive quantization\n",
        "    adjusted_quantizers = []\n",
        "    for r_uniform, r_hific in zip(uniform_rates.flatten(), rate_map.flatten()):\n",
        "        delta = r_uniform - r_hific\n",
        "        adjusted_quantizer = uniform_quantizer * (2 ** delta)\n",
        "        adjusted_quantizers.append(adjusted_quantizer)\n",
        "\n",
        "    # Reshape the adjusted quantizers to match the resized image dimensions\n",
        "    adjusted_quantizers = np.reshape(adjusted_quantizers, resized_img_array.shape[:-1])  # Now matches (32, 32)\n",
        "\n",
        "    return np.reshape(adjusted_quantizers, resized_img_array.shape[:-1])\n",
        "\n",
        "\n",
        "# Setup and model initialization\n",
        "model_choice = 'HIFIC-med'\n",
        "model_choices = {\n",
        "    'HIFIC-low': '1hfFTkZbs_VOBmXQ-M4bYEPejrD76lAY9',\n",
        "    'HIFIC-med': '1QNoX0AGKTBkthMJGPfQI0dT0_tnysYUb',\n",
        "    'HIFIC-high': '1BFYpvhVIA_Ek2QsHBbKnaBE8wn1GhFyA'\n",
        "}\n",
        "model_ID = model_choices[model_choice]\n",
        "\n",
        "# Download model checkpoint\n",
        "def get_model_checkpoint(output_dir, model_ID, model_choice):\n",
        "    output_path = os.path.join(output_dir, f'{model_choice.lower()}.pt')\n",
        "    if os.path.exists(output_path):\n",
        "        print('File already exists:', output_path)\n",
        "        return output_path\n",
        "    print('Downloading model...')\n",
        "    !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&id={model_ID}\" -O {output_path} && rm -rf /tmp/cookies.txt\n",
        "    return output_path\n",
        "\n",
        "model_path = get_model_checkpoint(CKPT_DIR, model_ID, model_choice)\n",
        "\n",
        "# Initialize HiFiC model\n",
        "first_model_init = False\n",
        "if first_model_init is False:\n",
        "    print('Building model...')\n",
        "    model, args = prepare_model(model_path, STAGING_DIR)\n",
        "    first_model_init = True\n",
        "\n",
        "# Upload or download images\n",
        "custom_image = False\n",
        "if custom_image:\n",
        "    uploaded = files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "        !mv -v $fn $INPUT_DIR\n",
        "else:\n",
        "    get_default_image(INPUT_DIR, \"portrait\")\n",
        "\n",
        "# Adaptive quantization and compression\n",
        "all_files = os.listdir(INPUT_DIR)\n",
        "for file_name in all_files:\n",
        "    full_path = os.path.join(INPUT_DIR, file_name)\n",
        "    adaptive_quantized = adaptive_quantization(model, full_path)\n",
        "\n",
        "    # Save the quantized image for compression\n",
        "    quantized_image_path = os.path.join(STAGING_DIR, 'quantized.png')\n",
        "    Image.fromarray(np.uint8(adaptive_quantized)).save(quantized_image_path)\n",
        "\n",
        "    # Compress the quantized image\n",
        "    data_loader = prepare_dataloader(args, STAGING_DIR, OUT_DIR)\n",
        "    compress_and_save(model, args, data_loader, OUT_DIR)\n",
        "\n",
        "# Display outputs\n",
        "all_outputs = []\n",
        "for compressed_file in glob.glob(os.path.join(OUT_DIR, '*.hfc')):\n",
        "    file_name, _ = os.path.splitext(compressed_file)\n",
        "    output_path = os.path.join(OUT_DIR, f'{file_name}.png')\n",
        "    reconstruction = load_and_decompress(model, compressed_file, output_path)\n",
        "    all_outputs.append(File(\n",
        "        output_path=output_path,\n",
        "        compressed_path=compressed_file,\n",
        "        num_bytes=os.path.getsize(compressed_file),\n",
        "        bpp=get_bpp(Image.open(output_path).size, os.path.getsize(compressed_file))\n",
        "    ))\n",
        "\n",
        "for file in all_outputs:\n",
        "    print(f'{file.output_path} | {file.bpp:.4f} bpp')\n",
        "    display(Image.open(file.output_path))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "18:27:46 INFO - logger_setup: /content/high-fidelity-generative-compression/compress.py\n",
            "INFO:src.helpers.utils:/content/high-fidelity-generative-compression/compress.py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists: /content/checkpoint/hific-med.pt\n",
            "Building model...\n",
            "Building prior probability tables...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:13<00:00,  4.77it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up Perceptual loss...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18:28:03 INFO - load_model: Loading model ...\n",
            "18:28:03 INFO - load_model: Loading model ...\n",
            "18:28:03 INFO - load_model: Loading model ...\n",
            "18:28:03 INFO - load_model: Loading model ...\n",
            "18:28:03 INFO - load_model: Loading model ...\n",
            "18:28:03 INFO - load_model: Loading model ...\n",
            "18:28:03 INFO - load_model: Loading model ...\n",
            "18:28:03 INFO - load_model: Loading model ...\n",
            "18:28:03 INFO - load_model: Loading model ...\n",
            "18:28:03 INFO - load_model: Loading model ...\n",
            "18:28:03 INFO - load_model: Loading model ...\n",
            "18:28:03 INFO - load_model: Loading model ...\n",
            "18:28:03 INFO - load_model: Loading model ...\n",
            "INFO:src.helpers.utils:Loading model ...\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Estimated model size (under fp32): 593.146 MB\n",
            "INFO:src.helpers.utils:Estimated model size (under fp32): 593.146 MB\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "18:28:03 INFO - load_model: Model init 16.961s\n",
            "INFO:src.helpers.utils:Model init 16.961s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /content/high-fidelity-generative-compression/src/loss/perceptual_similarity/weights/v0.1/alex.pth\n",
            "...[net-lin [alex]] initialized\n",
            "...Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Model loaded from disk.\n",
            "INFO:src.helpers.utils:Model loaded from disk.\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "18:28:04 INFO - prepare_model: Building hyperprior probability tables...\n",
            "INFO:src.helpers.utils:Building hyperprior probability tables...\n",
            "100%|██████████| 320/320 [00:00<00:00, 1907.08it/s]\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "18:28:08 INFO - prepare_model: All tables built.\n",
            "INFO:src.helpers.utils:All tables built.\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "18:28:09 INFO - compress_and_save: Starting compression...\n",
            "INFO:src.helpers.utils:Starting compression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input images\n",
            "['/content/stage/quantized.png']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Padding size should be less than the corresponding input dimension, but got: padding (0, 15) at dimension 3 of input [1, 3, 1024, 1]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-c8724ddb676a>\u001b[0m in \u001b[0;36m<cell line: 130>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Compress the quantized image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTAGING_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mcompress_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;31m# Display outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/high-fidelity-generative-compression/compress.py\u001b[0m in \u001b[0;36mcompress_and_save\u001b[0;34m(model, args, data_loader, output_dir)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# Perform entropy coding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mcompressed_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mout_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{filenames[0]}_compressed.hfc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/high-fidelity-generative-compression/src/model.py\u001b[0m in \u001b[0;36mcompress\u001b[0;34m(self, x, silent)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mn_encoder_downsamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_downsampling_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mn_encoder_downsamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# Encoder forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/high-fidelity-generative-compression/src/helpers/utils.py\u001b[0m in \u001b[0;36mpad_factor\u001b[0;34m(input_image, spatial_dims, factor)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspatial_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatial_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mpad_H\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfactor_H\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfactor_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfactor_H\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mpad_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfactor_W\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfactor_W\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfactor_W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Apply padding only if necessary and ensure padding is smaller than the image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   5094\u001b[0m                     \u001b[0;34m\"torch._decomp.decompositions\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5095\u001b[0m                 )._replication_pad(input, pad)\n\u001b[0;32m-> 5096\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Padding size should be less than the corresponding input dimension, but got: padding (0, 15) at dimension 3 of input [1, 3, 1024, 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPU2WMlMZviB"
      },
      "source": [
        "def get_default_image(output_dir, image_choice=\"portrait\"):\n",
        "    image_ID = dict(cafe=\"b1b8f33917a40c9d0b118ef801de67d4.png\",\n",
        "                    cat=\"4fa92b8ecb4ee46a942837447de1ac5c.png\",\n",
        "                    city=\"b98ec5b29d02ef65e57d23ef90660b4d.png\",\n",
        "                    clocktower=\"9cbf2594f339c0d3d0f0ea25c62af52b.png\",\n",
        "                    fresco=\"8181526d9f238726d3e1d3ec3cc56fb7.png\",\n",
        "                    islet=\"c6658d87c608b631f5cc3fb5a8d89731.png\",\n",
        "                    mountain=\"d3688a7285d7b2b81febe1cd72e6e22c.png\",\n",
        "                    pasta=\"f5be5054c01d8efc834d78a991356ad6.png\",\n",
        "                    pines=\"e903c4f4684100a6dbac1f0b9b4de760.png\",\n",
        "                    plaza=\"d78b363974ac79908b79012f48de715d.png\",\n",
        "                    portrait=\"ad249bba099568403dc6b97bc37f8d74.png\",\n",
        "                    shoreline=\"b9bad0c68eb9ce94e02e9698c8cc429a.png\",\n",
        "                    street=\"90b622e11ecc37edd42297427403ee81.png\",\n",
        "                    tundra=\"cc831c904a314a0e98530124526e930b.png\",\n",
        "                    )[image_choice]\n",
        "\n",
        "    default_image_url = os.path.join(DEFAULT_IMAGE_PREFIX, image_ID)\n",
        "    output_path = os.path.join(output_dir, os.path.basename(default_image_url))\n",
        "    print('Downloading', default_image_url, '\\n->', output_path)\n",
        "    urllib.request.urlretrieve(default_image_url, output_path)\n",
        "\n",
        "def get_model_checkpoint(output_dir, model_ID, model_choice, alternative=False,\n",
        "                         overwrite=False):\n",
        "    output_path = os.path.join(output_dir, f'{model_choice.lower()}.pt')\n",
        "    if overwrite is True:\n",
        "        print('Overwriting file, if it exists.')\n",
        "        !rm -v $output_path\n",
        "    else:\n",
        "        if os.path.exists(output_path):\n",
        "            print('File already exists at', '\\n->', output_path)\n",
        "            return output_path\n",
        "    print('Downloading model to', '\\n->', output_path)\n",
        "    if alternative is True:\n",
        "        !wget \"https://zenodo.org/record/4026003/files/$model_ID\" -O $output_path\n",
        "    else:\n",
        "        !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$model_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$model_ID\" -O $output_path && rm -rf /tmp/cookies.txt\n",
        "\n",
        "    return output_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiY97nwyJia9"
      },
      "source": [
        "## Select Model\n",
        "Higher bitrates result in higher-fidelity reconstructions, at the expense of increased message length. `HIFIC-low` is the model with the highest compression ratio (lowest output filesize), and `HIFIC-high` is the model with the lowest compression ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulxLn5j7n_an"
      },
      "source": [
        "# Enter choice to right\n",
        "model_choice = 'HIFIC-med' #@param [\"HIFIC-low\", \"HIFIC-med\", \"HIFIC-high\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA9r_M230r7x"
      },
      "source": [
        "Clone repo and grab the model checkpoint (around 2 GB). Please check the downloaded filesize carefully - see below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOPsakQLKJGr"
      },
      "source": [
        "# Drive IDs\n",
        "model_choices = {'HIFIC-low': '1hfFTkZbs_VOBmXQ-M4bYEPejrD76lAY9',\n",
        "                 'HIFIC-med': '1QNoX0AGKTBkthMJGPfQI0dT0_tnysYUb',\n",
        "                 'HIFIC-high': '1BFYpvhVIA_Ek2QsHBbKnaBE8wn1GhFyA'}\n",
        "\n",
        "model_ID = model_choices[model_choice]\n",
        "model_path = get_model_checkpoint(CKPT_DIR, model_ID, model_choice)\n",
        "first_model_init = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seLrm41t1wQd"
      },
      "source": [
        "# Checkpoints should be around 2GB in size - if not, run the next\n",
        "# cell to download models from an alternate host\n",
        "!ls -ltrh /content/checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrTVlxyi3I83"
      },
      "source": [
        "During periods of high traffic the download quota for Google Drive may be temporarily exceeded. Please check (`ls -ltrh /content/checkpoint`) if the checkpoints are around 1.5GB - 2 GB in size. If the filesize is in kB, run the cell below this to download the model checkpoints from Zenodo - this may be slower but more robust."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPIEzUK317Hn"
      },
      "source": [
        "# Don't run this if the download from Drive was successful!\n",
        "model_choices = {'HIFIC-low': 'hific_low.pt?download=1',\n",
        "                 'HIFIC-med': 'hific_med.pt?download=1',\n",
        "                 'HIFIC-high': 'hific_hi.pt?download=1'}\n",
        "\n",
        "model_ID = model_choices[model_choice]\n",
        "model_path = get_model_checkpoint(CKPT_DIR, model_ID, model_choice,\n",
        "                                  alternative=True, overwrite=True)\n",
        "first_model_init = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-50mPz02cKo"
      },
      "source": [
        "# Checkpoints should be around 2GB in size\n",
        "!ls -ltrh /content/checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a0vpM2j1EBz"
      },
      "source": [
        "!git clone https://github.com/Justin-Tan/high-fidelity-generative-compression.git\n",
        "%cd high-fidelity-generative-compression/\n",
        "from compress import prepare_model, prepare_dataloader, compress_and_save, load_and_decompress, compress_and_decompress"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7ptGgrzkATB"
      },
      "source": [
        "## Prepare Images\n",
        "\n",
        "To upload your own images (JPG or PNG without alpha channels), set `custom_image=True` in the following cell. Otherwise, we'll use a default image from the CLIC2020 Compression Challenge dataset.\n",
        "\n",
        "Alternatively, you can use the `Files` tab on the left and select the `Upload to session storage` icon to upload more custom images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJZlFxcNyK2M"
      },
      "source": [
        "custom_image = False #@param [\"False\", \"True\"] {type:\"raw\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37LNwIexHmu8"
      },
      "source": [
        "# Choose default images from CLIC2020 dataset\n",
        "# Skip if uploading custom images\n",
        "default_image = \"portrait\" #@param [\"cafe\", \"cat\", \"city\", \"clocktower\", \"fresco\", \"islet\", \"mountain\", \"pasta\", \"pines\", \"plaza\", \"portrait\", \"shoreline\", \"street\", \"tundra\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_S4bo4vhU_P"
      },
      "source": [
        "if custom_image is True:\n",
        "    print('Using user-defined images.')\n",
        "    # Get dict of upload files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "        print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "            name=fn, length=len(uploaded[fn])))\n",
        "        !mv -iv $fn $INPUT_DIR\n",
        "else:\n",
        "    print('Using default image.')\n",
        "    # Download default image\n",
        "    get_default_image(INPUT_DIR, default_image)\n",
        "\n",
        "all_files = os.listdir(INPUT_DIR)\n",
        "print(f'Got following files ({len(all_files)}):')\n",
        "scale_factor = 2 if len(all_files) == 1 else 4\n",
        "\n",
        "for file_name in all_files:\n",
        "    img = Image.open(os.path.join(INPUT_DIR, file_name))\n",
        "    w, h = img.size\n",
        "    img = img.resize((w // scale_factor, h // scale_factor))\n",
        "    print('-> ' + file_name + ':')\n",
        "    display(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd02HOhLBj6e"
      },
      "source": [
        "SUPPORTED_EXT = {'.png', '.jpg'}\n",
        "\n",
        "all_files = os.listdir(INPUT_DIR)\n",
        "if not all_files:\n",
        "    raise ValueError(\"Please upload/download images!\")\n",
        "\n",
        "def get_bpp(image_dimensions, num_bytes):\n",
        "    w, h = image_dimensions\n",
        "    return num_bytes * 8 / (w * h)\n",
        "\n",
        "def has_alpha(img_p):\n",
        "    im = Image.open(img_p)\n",
        "    return im.mode == 'RGBA'\n",
        "\n",
        "!rm -v $STAGING_DIR/*\n",
        "\n",
        "for file_name in all_files:\n",
        "    if os.path.isdir(file_name):\n",
        "        continue\n",
        "    if not any(file_name.endswith(ext) for ext in SUPPORTED_EXT):\n",
        "        print('Skipping non-image', file_name, '...')\n",
        "        continue\n",
        "    full_path = os.path.join(INPUT_DIR, file_name)\n",
        "    if has_alpha(full_path) is True:\n",
        "        print('Skipping because of alpha channel:', file_name)\n",
        "        continue\n",
        "\n",
        "    file_name, _ = os.path.splitext(file_name)\n",
        "    original_sizes[file_name] = os.path.getsize(full_path)\n",
        "    output_path = os.path.join(OUT_DIR, f'{file_name}.png')\n",
        "    !mv -v $full_path $STAGING_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nYQ1lZpwWG-"
      },
      "source": [
        "## Enabling GPU\n",
        "\n",
        "GPU should be enabled for this Colab. If the next cell prints a warning, do the following:\n",
        "- Navigate to `Edit →> Notebook Settings`\n",
        "- Select GPU from the Hardware Accelerator drop-down\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0U-OwqpwZsv"
      },
      "source": [
        "if torch.cuda.is_available() is False:\n",
        "  print('WARNING: No GPU found. Compression/decompression will be slow!')\n",
        "else:\n",
        "  print(f'Found GPU {torch.cuda.get_device_name(0)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzaWP_G9w0Wh"
      },
      "source": [
        "# Compress Images\n",
        "Note: Models can take up to a minute to load on Colab, depending on the allocated GPU and chosen model - you only need to run the following cell once per session.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeIsfPxcG1Ro"
      },
      "source": [
        "# Setup model\n",
        "if first_model_init is False:\n",
        "    print('Building model ...')\n",
        "    model, args = prepare_model(model_path, STAGING_DIR)\n",
        "    first_model_init = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij6avY8OyG4I"
      },
      "source": [
        "Encode images and save compressed format to disk. Note: depending on the allocated GPU, large images (`>~ 4000x4000 px`) may throw an OOM error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHgSCmS5RRZ1"
      },
      "source": [
        "%%time\n",
        "data_loader = prepare_dataloader(args, STAGING_DIR, OUT_DIR)\n",
        "compress_and_save(model, args, data_loader, OUT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FARMLHaa1Crt"
      },
      "source": [
        "# Check compressed filesizes\n",
        "!ls -ltrh $OUT_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnxLDQ1SyNMU"
      },
      "source": [
        "Load compressed format from disk and decode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xwUN5HRRVSk"
      },
      "source": [
        "all_outputs = []\n",
        "\n",
        "for compressed_file in glob.glob(os.path.join(OUT_DIR, '*.hfc')):\n",
        "    file_name, _ = os.path.splitext(compressed_file)\n",
        "    output_path = os.path.join(OUT_DIR, f'{file_name}.png')\n",
        "\n",
        "    # Model decode\n",
        "    reconstruction = load_and_decompress(model, compressed_file, output_path)\n",
        "\n",
        "    all_outputs.append(File(output_path=output_path,\n",
        "                            compressed_path=compressed_file,\n",
        "                            num_bytes=os.path.getsize(compressed_file),\n",
        "                            bpp=get_bpp(Image.open(output_path).size, os.path.getsize(compressed_file))))\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQhQQs-CTkgy"
      },
      "source": [
        "# Show output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nVCPeDnskD8"
      },
      "source": [
        "def print_html(html):\n",
        "    display(HTML(html + '<br/>'))\n",
        "\n",
        "def make_cell_large():\n",
        "    display(Javascript(\n",
        "        '''google.colab.output.setIframeHeight(0, true, {maxHeight: 5192})'''))\n",
        "\n",
        "make_cell_large()  # Larger output window.\n",
        "\n",
        "for file in all_outputs:\n",
        "    print_html('<hr/>')\n",
        "    file_name, _ = os.path.splitext(file.output_path)\n",
        "    original_size = original_sizes[os.path.basename(file_name).split('_compressed')[0]]\n",
        "    print(f'Showing {file.output_path} | {file.num_bytes//1000} kB (compressed) | {file.bpp:.4f} bpp | Original: {original_size//1000} kB')\n",
        "    display(Image.open(file.output_path))\n",
        "    print_html('<hr/>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-1g_eP5tuW_"
      },
      "source": [
        "You can compress new images by going back to the \"Prepare Images\" heading and selecting a different default image or upload your own for compression, then running the cells below in sequence. Note that each model cannot decompress the output generated by a different model, and you need to delete the contents of `/content/out` if you want to try a different model.\n",
        "\n",
        "Please open an issue if you encounter an error when running this demo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b-wkBnyrTAR"
      },
      "source": [
        "### Download compressed images\n",
        "\n",
        "Note: Files are losslessly saved as PNG for viewing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn3epZhUYWOw"
      },
      "source": [
        "download_outputs = True #@param [\"False\", \"True\"] {type:\"raw\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BKccvcTpj1k"
      },
      "source": [
        "if download_outputs is True:\n",
        "    ZIP = '/content/hific_compressed_images.zip'\n",
        "\n",
        "    with zipfile.ZipFile(ZIP, 'w') as zf:\n",
        "        for f in all_outputs:\n",
        "            path_with_bpp = f.output_path.replace('.png', f'-{f.bpp:.3f}bpp.png')\n",
        "            zf.write(f.output_path, os.path.basename(path_with_bpp))\n",
        "\n",
        "    files.download(ZIP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo8Jo47741ih"
      },
      "source": [
        "# Citation\n",
        "\n",
        "This is a re-implementation of the orignal paper. Please cite the [original paper](https://arxiv.org/abs/2006.09965) if you use their work.\n",
        "\n",
        "```bash\n",
        "@article{mentzer2020high,\n",
        "  title={High-Fidelity Generative Image Compression},\n",
        "  author={Mentzer, Fabian and Toderici, George and Tschannen, Michael and Agustsson, Eirikur},\n",
        "  journal={arXiv preprint arXiv:2006.09965},\n",
        "  year={2020}\n",
        "}\n",
        "```"
      ]
    }
  ]
}